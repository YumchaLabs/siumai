//! Usage statistics types.
//!
//! This module defines token usage structures shared across providers.

use serde::{Deserialize, Serialize};

/// Usage statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    /// Input tokens used
    pub prompt_tokens: u32,
    /// Output tokens generated
    pub completion_tokens: u32,
    /// Total tokens used
    pub total_tokens: u32,
    /// Cached tokens (if applicable)
    #[deprecated(
        since = "0.11.0",
        note = "Use prompt_tokens_details.cached_tokens instead"
    )]
    pub cached_tokens: Option<u32>,
    /// Reasoning tokens (for models like o1)
    #[deprecated(
        since = "0.11.0",
        note = "Use completion_tokens_details.reasoning_tokens instead"
    )]
    pub reasoning_tokens: Option<u32>,
    /// Detailed breakdown of prompt tokens
    #[serde(skip_serializing_if = "Option::is_none")]
    pub prompt_tokens_details: Option<PromptTokensDetails>,
    /// Detailed breakdown of completion tokens
    #[serde(skip_serializing_if = "Option::is_none")]
    pub completion_tokens_details: Option<CompletionTokensDetails>,
}

/// Breakdown of tokens used in the prompt
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct PromptTokensDetails {
    /// Audio input tokens present in the prompt
    #[serde(skip_serializing_if = "Option::is_none")]
    pub audio_tokens: Option<u32>,
    /// Cached tokens present in the prompt
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cached_tokens: Option<u32>,
}

/// Breakdown of tokens used in the completion
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct CompletionTokensDetails {
    /// Tokens generated by the model for reasoning
    #[serde(skip_serializing_if = "Option::is_none")]
    pub reasoning_tokens: Option<u32>,
    /// Audio output tokens generated by the model
    #[serde(skip_serializing_if = "Option::is_none")]
    pub audio_tokens: Option<u32>,
    /// Accepted prediction tokens (when using Predicted Outputs)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub accepted_prediction_tokens: Option<u32>,
    /// Rejected prediction tokens (when using Predicted Outputs)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub rejected_prediction_tokens: Option<u32>,
}

impl Usage {
    /// Create new usage statistics
    pub const fn new(prompt_tokens: u32, completion_tokens: u32) -> Self {
        Self {
            prompt_tokens,
            completion_tokens,
            total_tokens: prompt_tokens + completion_tokens,
            #[allow(deprecated)]
            cached_tokens: None,
            #[allow(deprecated)]
            reasoning_tokens: None,
            prompt_tokens_details: None,
            completion_tokens_details: None,
        }
    }

    /// Create a builder for constructing Usage with detailed token information
    pub fn builder() -> UsageBuilder {
        UsageBuilder::default()
    }

    /// Create usage with all fields (for backward compatibility during migration)
    #[allow(deprecated)]
    pub fn with_legacy_fields(
        prompt_tokens: u32,
        completion_tokens: u32,
        total_tokens: u32,
        cached_tokens: Option<u32>,
        reasoning_tokens: Option<u32>,
    ) -> Self {
        Self {
            prompt_tokens,
            completion_tokens,
            total_tokens,
            cached_tokens,
            reasoning_tokens,
            prompt_tokens_details: None,
            completion_tokens_details: None,
        }
    }

    /// Merge usage statistics
    pub fn merge(&mut self, other: &Usage) {
        self.prompt_tokens += other.prompt_tokens;
        self.completion_tokens += other.completion_tokens;
        self.total_tokens += other.total_tokens;

        // Merge deprecated fields for backward compatibility
        #[allow(deprecated)]
        {
            if let Some(cached) = other.cached_tokens {
                self.cached_tokens = Some(self.cached_tokens.unwrap_or(0) + cached);
            }
            if let Some(reasoning) = other.reasoning_tokens {
                self.reasoning_tokens = Some(self.reasoning_tokens.unwrap_or(0) + reasoning);
            }
        }

        // Merge detailed fields
        if let Some(ref other_details) = other.prompt_tokens_details {
            let self_details = self
                .prompt_tokens_details
                .get_or_insert_with(Default::default);
            if let Some(audio) = other_details.audio_tokens {
                self_details.audio_tokens = Some(self_details.audio_tokens.unwrap_or(0) + audio);
            }
            if let Some(cached) = other_details.cached_tokens {
                self_details.cached_tokens = Some(self_details.cached_tokens.unwrap_or(0) + cached);
            }
        }
        if let Some(ref other_completion_details) = other.completion_tokens_details {
            let self_details = self
                .completion_tokens_details
                .get_or_insert_with(Default::default);
            if let Some(reasoning) = other_completion_details.reasoning_tokens {
                self_details.reasoning_tokens =
                    Some(self_details.reasoning_tokens.unwrap_or(0) + reasoning);
            }
            if let Some(audio) = other_completion_details.audio_tokens {
                self_details.audio_tokens = Some(self_details.audio_tokens.unwrap_or(0) + audio);
            }
            if let Some(accepted) = other_completion_details.accepted_prediction_tokens {
                self_details.accepted_prediction_tokens =
                    Some(self_details.accepted_prediction_tokens.unwrap_or(0) + accepted);
            }
            if let Some(rejected) = other_completion_details.rejected_prediction_tokens {
                self_details.rejected_prediction_tokens =
                    Some(self_details.rejected_prediction_tokens.unwrap_or(0) + rejected);
            }
        }
    }
}

/// Builder for constructing Usage with detailed token information
#[derive(Default)]
pub struct UsageBuilder {
    prompt_tokens: u32,
    completion_tokens: u32,
    total_tokens: Option<u32>,
    prompt_details: Option<PromptTokensDetails>,
    completion_details: Option<CompletionTokensDetails>,
}

impl UsageBuilder {
    /// Set prompt tokens
    pub fn prompt_tokens(mut self, tokens: u32) -> Self {
        self.prompt_tokens = tokens;
        self
    }

    /// Set completion tokens
    pub fn completion_tokens(mut self, tokens: u32) -> Self {
        self.completion_tokens = tokens;
        self
    }

    /// Set total tokens (if not set, will be calculated as prompt + completion)
    pub fn total_tokens(mut self, tokens: u32) -> Self {
        self.total_tokens = Some(tokens);
        self
    }

    /// Add cached tokens to prompt details
    pub fn with_cached_tokens(mut self, cached: u32) -> Self {
        let details = self.prompt_details.get_or_insert_with(Default::default);
        details.cached_tokens = Some(cached);
        self
    }

    /// Add audio input tokens to prompt details
    pub fn with_prompt_audio_tokens(mut self, audio: u32) -> Self {
        let details = self.prompt_details.get_or_insert_with(Default::default);
        details.audio_tokens = Some(audio);
        self
    }

    /// Add reasoning tokens to completion details
    pub fn with_reasoning_tokens(mut self, reasoning: u32) -> Self {
        let details = self.completion_details.get_or_insert_with(Default::default);
        details.reasoning_tokens = Some(reasoning);
        self
    }

    /// Add audio output tokens to completion details
    pub fn with_completion_audio_tokens(mut self, audio: u32) -> Self {
        let details = self.completion_details.get_or_insert_with(Default::default);
        details.audio_tokens = Some(audio);
        self
    }

    /// Add accepted prediction tokens to completion details
    pub fn with_accepted_prediction_tokens(mut self, accepted: u32) -> Self {
        let details = self.completion_details.get_or_insert_with(Default::default);
        details.accepted_prediction_tokens = Some(accepted);
        self
    }

    /// Add rejected prediction tokens to completion details
    pub fn with_rejected_prediction_tokens(mut self, rejected: u32) -> Self {
        let details = self.completion_details.get_or_insert_with(Default::default);
        details.rejected_prediction_tokens = Some(rejected);
        self
    }

    /// Set prompt token details directly
    pub fn with_prompt_details(mut self, details: PromptTokensDetails) -> Self {
        self.prompt_details = Some(details);
        self
    }

    /// Set completion token details directly
    pub fn with_completion_details(mut self, details: CompletionTokensDetails) -> Self {
        self.completion_details = Some(details);
        self
    }

    /// Build the Usage struct
    #[allow(deprecated)]
    pub fn build(self) -> Usage {
        let total = self
            .total_tokens
            .unwrap_or(self.prompt_tokens + self.completion_tokens);

        Usage {
            prompt_tokens: self.prompt_tokens,
            completion_tokens: self.completion_tokens,
            total_tokens: total,
            cached_tokens: self.prompt_details.as_ref().and_then(|d| d.cached_tokens),
            reasoning_tokens: self
                .completion_details
                .as_ref()
                .and_then(|d| d.reasoning_tokens),
            prompt_tokens_details: self.prompt_details,
            completion_tokens_details: self.completion_details,
        }
    }
}

impl PromptTokensDetails {
    /// Create with only cached tokens
    pub fn with_cached(cached: u32) -> Self {
        Self {
            audio_tokens: None,
            cached_tokens: Some(cached),
        }
    }

    /// Create with only audio tokens
    pub fn with_audio(audio: u32) -> Self {
        Self {
            audio_tokens: Some(audio),
            cached_tokens: None,
        }
    }
}

impl CompletionTokensDetails {
    /// Create with only reasoning tokens
    pub fn with_reasoning(reasoning: u32) -> Self {
        Self {
            reasoning_tokens: Some(reasoning),
            audio_tokens: None,
            accepted_prediction_tokens: None,
            rejected_prediction_tokens: None,
        }
    }

    /// Create with only audio tokens
    pub fn with_audio(audio: u32) -> Self {
        Self {
            reasoning_tokens: None,
            audio_tokens: Some(audio),
            accepted_prediction_tokens: None,
            rejected_prediction_tokens: None,
        }
    }
}
